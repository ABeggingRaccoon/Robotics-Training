{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](../../index.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRC Analytics with Python - Session 10\n",
    "# File Operations and Comprehensions\n",
    "**Last Updated: 6 October 2021**  \n",
    "\n",
    "Honestly, file operations and comprehensions don't have much in common with each other. They are combined here because they fit together nicely in one session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If Using Google Colab\n",
    "It's best if you clone the *pyclass_frc* Github repo and run this notebook from your local computer. But if you would like to run it from Google Colab, uncomment and run the two lines in the next cell. (*Don't delete the exclamation points at the start of the line!*) They will download several data files into the local folder on Google Colab. The files are needed to run the examples and do the exercises in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -nv https://raw.githubusercontent.com/irs1318dev/pyclass_frc/master/sessions/s09_files_and_comprehensions/get_files_s9.sh\n",
    "# !bash get_files_s9.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. File Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Reading Data From a Text File\n",
    "I'm sure you all understand why the ability to read or write to files is essential. So we'll just jump right in.\n",
    "\n",
    "Python contains a built-in function called `open()`, which we'll use to work with files. Let's open and read data from our first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Wit and Wisdom of Grace Hopper\n",
      "\"Life was simple before World War II. After that, we had systems.\"\n",
      "That observation comes from one who was present at the creation of the age of systems -- Rear Admiral Grace Hopper (US Navy, Retired), who spoke on the campus of the Ohio State University, Columbus, on Feb. 5, 1987, as part of a year-long celebration of the twentieth anniversary of the formation of the Department of Computer and Information Science.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Opening a file and displaying contents\n",
    "txtfile = open(r\"hopper.txt\", \"rt\")     # Line 1\n",
    "txt = txtfile.read()                    # Line 2\n",
    "txtfile.close()                         # Line 3\n",
    "print(txt[:454])                        # Line 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Line 1 - The `open()` Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. First Parameter - File Path\n",
    "First, in line 1, we called the `open()` function and the first paramter was a file name, `\"hopper.txt\"`. As written, with just the file name, the `open()` function will expect the *hopper.txt* file to be located in the same folder as this notebook. If *hopper.txt* were located in some other folder, `open()` would throw an error. There are several ways to tell `open()` to look in different folders.\n",
    "\n",
    "* **Relative Path to Subfolder:** Referring to files in subfolders of the current folder is easy. Just prepend the folder name and a forward slash to the file name. For example, if *hopper.txt* was in a subfolder called *text_files*, we would pass this value to `open()`: *`\"text_files/hopper.txt\"`*\n",
    "* **Relative Path to Parent Folder:** Adding two periods (*`..`*) to the path tells Python to go to up one folder. For example, if *hopper.txt* was located in the parent folder of this notebook, we would pass *`\"../hopper.txt\"`* to `open()`. If *hopper.txt* was two folders up, we would pass *`\"../../hopper.txt\"`*.\n",
    "* **Relative Paths to Sibling Folders:** The techniques in the previous two examples can be combined to get to a sibling folder. For example, *`\"../brilliant_computer_scientists/hopper.txt\"`* will jump up to a parent folder and then down to a sibling folder called *brilliant_computer_scientists*.\n",
    "* **Absolute Paths:** An absolute path, starting with the root folder, can refer to any file on the computer. For example, *`\"C:/Users/stacy/Projects/pyclass_frc/sessions/s10_comprehensions_and_files/hopper.txt\"`* is an absolute path on a Windows computer.  On a linux system the path might look like *`\"/home/Users/stacy/Projects/pyclass_frc/sessions/s10_comprehensions_and_files/hopper.txt\"`* and on an apple computer it might look like *`\"/Users/stacy/Projects/pyclass_frc/sessions/s10_comprehensions_and_files/hopper.txt\"`*\n",
    "\n",
    "Avoid absolute paths. If we used the path *`\"C:/Users/stacy/Projects/pyclass_frc/sessions/s10_comprehensions_and_files/hopper.txt\"`* to get to the *hopper.txt* file, then the code would only work for users named Stacy who are using a Windows machine. It's better to use relative paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Changing the Working Directory\n",
    "An alternative to passing long file paths to the `open()` function is to change the working directory. Unless you specify otherwise, Python will assume all files are located in the working directory. Let's display our current working directory for this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pperv\\\\Desktop\\\\Robotics\\\\Robotics Training\\\\pyclass_frc\\\\sessions\\\\s09_files_and_comprehensions'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the current working directory (CWD)\n",
    "import os\n",
    "def_cwd = os.getcwd()\n",
    "def_cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `getcwd()` function in the `os` module displays the current working directory.\n",
    "By default, the working directory for a Jupyter notebook is the folder that the notebook file (*.ipynb* file) is stored in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pperv\\\\Desktop\\\\Robotics\\\\Robotics Training\\\\pyclass_frc\\\\sessions\\\\s09_files_and_comprehensions\\\\misc_files'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the CWD\n",
    "os.chdir(\"misc_files\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current working directory is now the *misc_files* folder. Let's change back to our original working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pperv\\\\Desktop\\\\Robotics\\\\Robotics Training\\\\pyclass_frc\\\\sessions\\\\s09_files_and_comprehensions'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore the original CWD\n",
    "os.chdir(def_cwd)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Working Directory for Modules Run from Command Line\n",
    "The situtation is a little different when running Python modules from a command line. To demonstrate, we've placed a simple python module, *cwd.py* in the *misc_files* folder. The *cwd.py* file prints it's current working directory. Here are it's contents:\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "print()\n",
    "print(\"Current Working Directory\")\n",
    "print(os.getcwd())\n",
    "```\n",
    "\n",
    "Let's see what the CWD is when we run *cwd.py* from a parent folder. We can execute CLI commands from a *Jupyter* code cell by starting the line with `!`. On MS Windows, Jupyter uses the command prompt for CLI commands. If you've downloaded the course and are running it on your local computer, run the first cell. If you are using Google Colab, Mac, or Linux, run the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd.py\n",
      "districts.json\n",
      "matches.json\n",
      "temp.json\n",
      "TTY33ASR.jpg\n",
      "YaleNews_hopper-grace.UNIVAC.102635875-CC_0.jpg\n"
     ]
    }
   ],
   "source": [
    "# First, verify that cwd.py is located in the misc_files subfolder.\n",
    "!dir misc_files /B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if using Mac, Google Colab, or Linux\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Working Directory\n",
      "C:\\Users\\pperv\\Desktop\\Robotics\\Robotics Training\\pyclass_frc\\sessions\\s09_files_and_comprehensions\n"
     ]
    }
   ],
   "source": [
    "# Run cwd.py from a parent folder\n",
    "!python misc_files/cwd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! The *cwd.py* file is located in the *misc_files* subfolder, but the current directory is not set to *misc_files*. It's set to the parent folder from which we *ran* *cwd.py*. Now let's run *cwd.py* from the *misc_files* subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Working Directory\n",
      "C:\\Users\\pperv\\Desktop\\Robotics\\Robotics Training\\pyclass_frc\\sessions\\s09_files_and_comprehensions\\misc_files\n"
     ]
    }
   ],
   "source": [
    "# Run cwd.py from it's own folder\n",
    "# Note that you can cram two commands onto one line with '&&'.\n",
    "!cd misc_files && python cwd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we first changed directories to *misc_files* and then ran *cwd.py* from that directory, Python's current working directory was set to *misc_files*. \n",
    "\n",
    "The bottom line is that when running a Python module from a command line, the current working diretory will initially be set to the *folder from which we ran the module*, not the folder the module is located in. These two folders will often be the same folder, but not always."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Second Parameter - The Mode Parameter\n",
    "The second parameter, `\"rt\"` specifies the mode. The first letter, `\"r\"`, specifies that we want to open the file for reading data. We can write data to a file by replacing `\"r\"` with `\"w\"`. If the file already exists, using `\"w\"` will overwrite the file. The value `\"x\"` can also be used to write data to a file. It will not overwrite an existing file, but will throw an error if the file already exists.\n",
    "\n",
    "The second character, `\"t\"`, is used for text files. For binary files, we would use `\"b\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### e. `Open()` Function's Return Value\n",
    "The `Open()` does not return the contents of the file, at least not directly. It returns a file object, which we saved to a variable named `txtfile`.\n",
    "\n",
    "[The full documentation for `open()` is here.](https://docs.python.org/3/library/functions.html#open)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Line 2 - Getting the Content of the File\n",
    "In line 2, we we called the `read()` method on the `txtfile` object. The `read()` method returned the entire contents of the text file as a string. We could also have used `readlines()`, which returns a list, where each list item is one row from the file. Python splits the file into rows using the newline character, '/n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the building of bigger computers: \"In pioneer days they used oxen for heavy pulling, and when one ox couldn't budge a log, they didn't try to grow a larger ox. We shouldn't be trying for bigger computers, but for more systems of computers.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Opening a file and using \n",
    "txtfile = open(r\"hopper.txt\", \"rt\")  # Line 1\n",
    "txtlist = txtfile.readlines()        # Line 2\n",
    "txtfile.close()                      # Line 3\n",
    "print(txtlist[18])                   # Line 4 - Famous Quote from Grace Hopper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `readlines()` method makes it easy to display just a single row from the text file. In our example we displayed the 19th line (remember, the first line has an index of 0), which contains a famous quote from\n",
    "Grace Hopper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Line 3 - Closing the File\n",
    "We called the `.close()` method in line 3 to close the file object. Methods like `read()` or `readlines()` won't work once the file is closed. In general, for small programs, nothing bad is going to happen if you don't explicitly close the file with `.close()`. Python will close the file automatically once the program or enclosing function exits. Still, bad things have been known to happen when programmers didn't close their files, so always close files when you are done with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Using the `with` Statement\n",
    "Programmers don't like to have to remember to do things like closing files. You can use a `with` statement to ensure files are closed when you are finished working with them. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1951 she discovered the first computer \"bug.\" It was a real moth, which she pasted into the UNIVAC I logbook. In 1952 she had an operational compiler. \"Nobody believed that,\" she said. \"I had a running compiler and nobody would touch it. They told me computers could only do arithmetic.\" Admiral Hopper is also the \"progenitor\" of COBOL, which she was working on in 1955. In 1967, she was recalled to the Navy and served with the Naval Data Automation Command until she retired. Her mission was to preside over the Navy's efforts to maintain uniformity in computer languages. In 1983 she earned a special Presidential appointment to flag rank as admiral. She is now a consultant for Digital Equipment Corporation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Opening a file and using \n",
    "with open(r\"hopper.txt\", \"rt\") as txtfile:  # Line 1\n",
    "    txtlist = txtfile.readlines()           # Line 2\n",
    "print(txtlist[15])                          # Line 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `with` statement is followed by an indented block of code. We work with the file object within the indented block. The file object will automatically be closed when we exit the indented block in line 3. Another benefit of using `with` is that if an error occurs in the indented block of code, Python will ensure that the file gets closed anyway. Using `with` is  a best practice for working with files in Python.\n",
    "\n",
    "The `with` statement can be used for things other than files. It is intended to be used with special objects called context managers. You can learn more than you probably want to know about context managers [at this link](https://docs.python.org/3/reference/datamodel.html#context-managers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. End of the Line\n",
    "If you were reading closely, then you noticed that we mentioned something about a *newline* character. A newline character is a special character used by Python to mark the end of a row in a text file, or to tell Python to move to a new row when displaying text. It can occur in a string just like any other character. In Python and many other programming languages, you can insert a newline character into a string using a backslash followed by an 'n', like so: `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is line 1.\\nThis is line 2.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_line_string = \"This is line 1.\\nThis is line 2.\"\n",
    "multi_line_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the results are not very impressive. The notebook is just displaying the newline character in the string. The outcome is better if we pass the string to the `print()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is line 1.\n",
      "This is line 2.\n"
     ]
    }
   ],
   "source": [
    "print(multi_line_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be thinking that `\\n` looks like *two* characters, not one. That's understandable, but Python's `ord()` function shows that `\\n` maps to a single character code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character code for newline: 10\n",
      "For comparison, character codes for IRS: [73, 82, 83]\n"
     ]
    }
   ],
   "source": [
    "print(\"Character code for newline:\", ord(\"\\n\"))\n",
    "# The next row uses a list comprehension, which will be covered later in\n",
    "#   this session.\n",
    "print(\"For comparison, character codes for IRS:\", [ord(c) for c in \"IRS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the backslash notation because our alphabet doesn't have a symbol that means newline. \"\\n\" is sometimes referred to as a control character, or a non-printable character, or an escape sequence character. There are other control characters in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include a backslash (\\) in a string with '\\\\'.\n",
      "Include quotation marks (\"\") in a string with '\\\"'.\n",
      "Include a tab character (\t) in a string with '\\t'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Include a backslash (\\\\) in a string with '\\\\\\\\'.\")\n",
    "print(\"Include quotation marks (\\\"\\\") in a string with '\\\\\\\"'.\")\n",
    "print(\"Include a tab character (\\t) in a string with '\\\\t'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically and historically, the '\\n' character is called a line feed character. Linux and older Unix operating systems use this character by default to mark the end of lines in text files. Microsoft Windows, on the other hand, uses two characters, a carriage return character ('\\r') and a line feed character ('\\n') to mark the end of a line. That's why, when you push files to a Github repository from Windows, you see all those messages about the end of line characters on the screen. Git is automatically converting your text files from using Windows style \"\\r\\n\" sequences to Linux style \"\\n\" sequences. And if it's not confusing enough that Windows and Linux use different characters to mark the end of a line, consider that old Apple Macintosh operating systems used just a carriage return ('\\r') to mark the end of a line.\n",
    "\n",
    "**Warning: Historical Stuff that is Interesting to your Mentor and Probably No One Else!**  \n",
    "How did it get to be this way? Video monitors were nonexistant or uncommon before the late 1970s. Anyone who wanted to interact in real time with a computer used a teleprinter, like the one pictured below.\n",
    "![Vintage Teletype](misc_files/TTY33ASR.jpg)\n",
    "\n",
    "The user would type commands on the teletype, seeing what they typed on a sheet of paper. They would hit a key to send the command to a computer, and the output from the command would print out on the paper. The command line interface that we are currently using is an on-screen version of the old teletype interface. The print head would move left to right across the page and the paper would be moved up and down by the roller. To start typing a new line, the user would hit the *RE-TURN* key to move the print head back to the left side of the page, and the *LINE FEED* key to move the paper up one row, effectively moving the print head down to the beginning of the next line.\n",
    "\n",
    "So why does Windows use '\\r\\n' line endings while Linux uses just '\\n'? Microsoft Windows uses '\\r\\n' because Microsoft's earlier operating system, MS-DOS, used '\\r\\n'. MS-DOS used '\\r\\n' because back in about 1980 when MS-DOS was being developed, they wanted MS-DOS to be compatible with another popular micro-computer operating system called CP/M, which had been developed in 1974 at a company called Digital Equipment Corporation. CP/M used '\\r\\n' because that sequence worked better for sending text to teletype machines like the ASR-33 teletype pictured above.\n",
    "\n",
    "Linux doesn't use '\\r\\n' because Linux was designed to be compatible with an older operating system called Unix (Bell Labs, 1969), which itself was inspired by an even older operating system called MULTICS (Cooperattive project of MIT, Bel Labs, and General Electric, 1964). MULTICS used a device driver to communicate with the teletype (very innovative at the time). So text files could contain the simpler '\\n' line ending and the device driver would convert '\\n' to whatever sequence of characters the teletype needed to advance to the next line.\n",
    "\n",
    "So there you have it. Windows uses '\\r\\n' because the developers of CP/M  in 1974 didn't use a device driver to talk to teletype machines. This might have been due to CP/M being a single-tasking operating system designed to work on small computers with 8-bit processors and no more than 64 kilobytes of memory. I'm guessing there was not a lot of extra bandwidth to be running a device driver. MULTICS, on the other hand, was designed to run on more powerful mainframe computers, like the GE-600 series.\n",
    "\n",
    "**And Now Back to Modern Times**  \n",
    "Most of the tools used by our robotics team take care of newline sequences without much trouble, so there's no need to memorize all of the different end of line sequences. But differences between newline sequences have caused headaches for many people in the past and could do so again in the future, so it's important to understand that different operating systems use different sequences. For Python, just use '\\n'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Writing to a Text File\n",
    "Here is an example of writing text to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing Text to a File\n",
    "with open(\"numfile.txt\", \"wt\") as numfile:\n",
    "    for num in range(5):\n",
    "        line = num * \" \" + str(num) + \"\\n\"\n",
    "        numfile.write(line)\n",
    "    for num in range(5, -1, -1):\n",
    "        line = num * \" \" + str(num) + \"\\n\"\n",
    "        numfile.write(line)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for writing to a file looks almost exactly the same as the code for reading a file. There are only a couple differences.\n",
    "* We just replaced \"r\" with \"w\" in the second parameter of the `open()` method.\n",
    "* We used the file object's `.write()` method. Note that we have to manually insert a newline character at the end of each line.\n",
    "\n",
    "We could use the `print()` function instead of `.write()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing print()\n",
    "with open(\"numfile.txt\", \"wt\") as numfile:\n",
    "    for num in range(5):\n",
    "        print(num * \" \" + str(num), file=numfile)\n",
    "    for num in range(5, -1, -1):\n",
    "        print(num * \" \" + str(num), file=numfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't have to manually add a newline character since `print()` appends a newline character to the output by default. We did have to pass the file object to the `file` parameter. Let's see what the file looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " 1\n",
      "  2\n",
      "   3\n",
      "    4\n",
      "     5\n",
      "    4\n",
      "   3\n",
      "  2\n",
      " 1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "with open(\"numfile.txt\", \"rt\") as numfile:\n",
    "    for line in numfile:\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sample above shows that for text files, we can iterate over each line in the file. Note that becase each lin already contains a newline character, we used the `print()` function's `end` parameter to disable the newline at the end of each line. This keeps the output from being double-spaced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. JSON Files\n",
    "JSON, which stands for Javascript Object Notation, refers to a technique for exchanging and storing structured data as text. As you might guess from the name, JSON is derived from Javascript, but it is now used in many systems and programming languages. Let's take a look at a simple JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"abbreviation\": \"chs\", \n",
      "  \"display_name\": \"FIRST Chesapeake\", \n",
      "  \"key\": \"2020chs\", \n",
      "  \"year\": 2020\n",
      " }, \n",
      " {\n",
      "  \"abbreviation\": \"fim\", \n",
      "  \"display_name\": \"FIRST In Michigan\", \n",
      "  \"key\": \"2020fim\", \n",
      "  \"year\": 2020\n",
      " }, \n"
     ]
    }
   ],
   "source": [
    "# Open a text file that contains information formatted as JSON\n",
    "with open(\"misc_files/districts.json\", \"rt\") as jfile:\n",
    "    for lin_num, line in enumerate(jfile):\n",
    "        print(line, end=\"\")\n",
    "        if lin_num > 11:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the first dozen or so lines are displayed to save space. The *districts.json* file contains information about all FIRST competition districts. Unlike the information in the *hopper.txt* file, which contains freeform text, the contents of *districts.json* must comply with a strict format.\n",
    "* Sequences of items are enclosed in square brackets, like a Python list.\n",
    "* Groups of key-value pairs are enclosed in curly braces, like a Python dictionary.\n",
    "* Items are separated by commas\n",
    "* Key-value pairs are separated by colons.\n",
    "* All text is enclosed in quotes.\n",
    "\n",
    "The *hopper.txt* file contains unstructured data, whereas the *districts.json* file contains structured data.\n",
    "\n",
    "Python contains a handy JSON module that makes it easier to work with JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of object returned by `json.load()`: <class 'list'>\n",
      "Length of `districts` list: 11\n",
      "Object type for each element of `districts` list: <class 'dict'>\n",
      "\n",
      "First three elements of `districts` list:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'abbreviation': 'fim',\n",
       "  'display_name': 'FIRST In Michigan',\n",
       "  'key': '2020fim',\n",
       "  'year': 2020},\n",
       " {'abbreviation': 'fma',\n",
       "  'display_name': 'FIRST Mid-Atlantic',\n",
       "  'key': '2020fma',\n",
       "  'year': 2020},\n",
       " {'abbreviation': 'fnc',\n",
       "  'display_name': 'FIRST North Carolina',\n",
       "  'key': '2020fnc',\n",
       "  'year': 2020}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening and Exploring a JSON file\n",
    "import json\n",
    "\n",
    "with open(\"misc_files/districts.json\", \"rt\") as jfile:\n",
    "    districts = json.load(jfile)\n",
    "    \n",
    "print(\"Type of object returned by `json.load()`:\", type(districts))\n",
    "print(\"Length of `districts` list:\", len(districts))\n",
    "print(\"Object type for each element of `districts` list:\", type(districts[0]))\n",
    "print()\n",
    "print(\"First three elements of `districts` list:\")\n",
    "districts[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the `json.load()` method to read data from the file object, the JSON data is converted to a Python list of dictionary objects. We can save data to a JSON file in a similar fashion using `json.dump()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_temps = {\"description\":\n",
    "    {\"title\": \"Contiguous U.S., Average Temperature, January-December\",\n",
    "        \"units\": \"Degrees Fahrenheit\",\n",
    "        \"base_period\": \"1901-2000\",\n",
    "        \"missing\": \"-99\"},\n",
    "    \"data\": {\n",
    "        \"194012\": {\n",
    "            \"value\": \"51.89\",\n",
    "            \"anomaly\": \"-0.13\"},\n",
    "        \"196012\": {\n",
    "            \"value\": \"51.44\",\n",
    "            \"anomaly\": \"-0.58\"},\n",
    "        \"198012\": {\n",
    "            \"value\": \"52.39\",\n",
    "            \"anomaly\": \"0.37\"},\n",
    "        \"200012\": {\n",
    "            \"value\": \"53.27\",\n",
    "            \"anomaly\": \"1.25\"},\n",
    "        \"201612\": {\n",
    "            \"value\": \"54.92\",\n",
    "            \"anomaly\": \"2.90\"}}\n",
    "}\n",
    "with open(\"temps.json\", \"wt\") as tempfile:\n",
    "    json.dump(us_temps, tempfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Comprehensions\n",
    "Now we'll take a break from files and review list and dictionary comprehensions. Comprehensions are a compact syntax for generating lists and dictionaries. They can be faster than using for loops in some circumstances, but we probably won't see any difference with relatively small datasets we use for FRC. Still, the compact syntax is quite neat. Most Python devotees would consider it good form to use a comprehension in place of a for loop.\n",
    "\n",
    "Remember the `districts` JSON data object we used earlier? Suppose we wanted to build a list that contains just the district abbreviations. We could do that with a traditional `for` loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Lists\n",
    "Remember the `districts` JSON data object we used earlier? Suppose we wanted to build a list that contains just the district abbreviations. We could do that with a traditional `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'districts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12096/1252660170.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Quick Refresher on districts data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdistricts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'districts' is not defined"
     ]
    }
   ],
   "source": [
    "# Quick Refresher on districts data\n",
    "districts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chs', 'fim', 'fma', 'fnc', 'in', 'isr', 'ne', 'ont', 'pch', 'pnw', 'tx']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A for loop to build a list of district abbreviations.\n",
    "codes = []\n",
    "for district in districts:\n",
    "    codes.append(district[\"abbreviation\"])\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a list comprehension, we can build the list in just one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chs', 'fim', 'fma', 'fnc', 'in', 'isr', 'ne', 'ont', 'pch', 'pnw', 'tx']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List comprehension that buils a list of abbreviations\n",
    "codes = [district[\"abbreviation\"] for district in districts]\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've basically compressed the *for* loop into one line and put it inside the list's square brackets.\n",
    "\n",
    "We can also do filtering in a list comprehension. Suppose we only are interested in district abbreviations that start with 'f':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'districts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12096/853693235.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# List comprehension with filtering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mdistrict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"abbreviation\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdistrict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdistricts\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"abbreviation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"f\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'districts' is not defined"
     ]
    }
   ],
   "source": [
    "# List comprehension with filtering\n",
    "[district[\"abbreviation\"] for district in districts if district[\"abbreviation\"][0] == \"f\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Dictionaries\n",
    "We can also use comprehensions to generate dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': (1, 1),\n",
       " '2': (2, 4),\n",
       " '4': (4, 16),\n",
       " '5': (5, 25),\n",
       " '7': (7, 49),\n",
       " '8': (8, 64)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary of tuples with squares\n",
    "tuple_squares = {str(x): (x, x**2) for x in range(10) if x % 3 != 0}\n",
    "tuple_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a dictionary comprehension, we drafted expressions for both the dictionaries key and value, separated by a colon. The key and value expressions are evaluated for every output of the iterator following the `for` keyword. The `if` expression filters out values where `x` is equal to 3. Finally, the entire expression is placed in curly braces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. More Comprehension Examples\n",
    "The *matches.json* file contains the complete match results from the 2020 FIRST Robotics district competition at Glacier Peak High School in Snohomish, WA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"misc_files/matches.json\", \"rt\") as jfile:\n",
    "    matches = json.load(jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type of matches data: <class 'list'>\n",
      "Length of matches list: 89\n",
      "\n",
      "First match in list:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'actual_time': 1583104716,\n",
       " 'alliances': {'blue': {'dq_team_keys': [],\n",
       "   'score': 136,\n",
       "   'surrogate_team_keys': [],\n",
       "   'team_keys': ['frc2930', 'frc2976', 'frc4918']},\n",
       "  'red': {'dq_team_keys': [],\n",
       "   'score': 148,\n",
       "   'surrogate_team_keys': [],\n",
       "   'team_keys': ['frc4911', 'frc2910', 'frc4173']}},\n",
       " 'comp_level': 'f',\n",
       " 'event_key': '2020wasno',\n",
       " 'key': '2020wasno_f1m1',\n",
       " 'match_number': 1,\n",
       " 'post_result_time': 1583105046,\n",
       " 'predicted_time': 1583104822,\n",
       " 'score_breakdown': {'blue': {'adjustPoints': 0,\n",
       "   'autoCellPoints': 40,\n",
       "   'autoCellsBottom': 0,\n",
       "   'autoCellsInner': 2,\n",
       "   'autoCellsOuter': 7,\n",
       "   'autoInitLinePoints': 15,\n",
       "   'autoPoints': 55,\n",
       "   'controlPanelPoints': 0,\n",
       "   'endgamePoints': 55,\n",
       "   'endgameRobot1': 'Hang',\n",
       "   'endgameRobot2': 'Hang',\n",
       "   'endgameRobot3': 'Park',\n",
       "   'endgameRungIsLevel': 'NotLevel',\n",
       "   'foulCount': 0,\n",
       "   'foulPoints': 0,\n",
       "   'initLineRobot1': 'Exited',\n",
       "   'initLineRobot2': 'Exited',\n",
       "   'initLineRobot3': 'Exited',\n",
       "   'rp': 0,\n",
       "   'shieldEnergizedRankingPoint': False,\n",
       "   'shieldOperationalRankingPoint': False,\n",
       "   'stage1Activated': True,\n",
       "   'stage2Activated': False,\n",
       "   'stage3Activated': False,\n",
       "   'stage3TargetColor': 'Unknown',\n",
       "   'tba_numRobotsHanging': 2,\n",
       "   'tba_shieldEnergizedRankingPointFromFoul': False,\n",
       "   'techFoulCount': 0,\n",
       "   'teleopCellPoints': 26,\n",
       "   'teleopCellsBottom': 0,\n",
       "   'teleopCellsInner': 0,\n",
       "   'teleopCellsOuter': 13,\n",
       "   'teleopPoints': 81,\n",
       "   'totalPoints': 136},\n",
       "  'red': {'adjustPoints': 0,\n",
       "   'autoCellPoints': 32,\n",
       "   'autoCellsBottom': 0,\n",
       "   'autoCellsInner': 0,\n",
       "   'autoCellsOuter': 8,\n",
       "   'autoInitLinePoints': 15,\n",
       "   'autoPoints': 47,\n",
       "   'controlPanelPoints': 0,\n",
       "   'endgamePoints': 45,\n",
       "   'endgameRobot1': 'Park',\n",
       "   'endgameRobot2': 'Hang',\n",
       "   'endgameRobot3': 'None',\n",
       "   'endgameRungIsLevel': 'IsLevel',\n",
       "   'foulCount': 0,\n",
       "   'foulPoints': 0,\n",
       "   'initLineRobot1': 'Exited',\n",
       "   'initLineRobot2': 'Exited',\n",
       "   'initLineRobot3': 'Exited',\n",
       "   'rp': 0,\n",
       "   'shieldEnergizedRankingPoint': False,\n",
       "   'shieldOperationalRankingPoint': False,\n",
       "   'stage1Activated': True,\n",
       "   'stage2Activated': False,\n",
       "   'stage3Activated': False,\n",
       "   'stage3TargetColor': 'Unknown',\n",
       "   'tba_numRobotsHanging': 1,\n",
       "   'tba_shieldEnergizedRankingPointFromFoul': False,\n",
       "   'techFoulCount': 0,\n",
       "   'teleopCellPoints': 56,\n",
       "   'teleopCellsBottom': 0,\n",
       "   'teleopCellsInner': 4,\n",
       "   'teleopCellsOuter': 22,\n",
       "   'teleopPoints': 101,\n",
       "   'totalPoints': 148}},\n",
       " 'set_number': 1,\n",
       " 'time': 1583103960,\n",
       " 'videos': [{'key': 'QiegqWDKHOQ', 'type': 'youtube'},\n",
       "  {'key': 'tijqefvzxIs', 'type': 'youtube'},\n",
       "  {'key': '26XinRoNxf8', 'type': 'youtube'}],\n",
       " 'winning_alliance': 'red'}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Object type of matches data:\", type(matches))\n",
    "print(\"Length of matches list:\", len(matches))\n",
    "print()\n",
    "print(\"First match in list:\")\n",
    "matches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Understanding the Match Data\n",
    "The matches JSON data contains information on all of the matches, includng both qualification and playoffs. The *comp_level* key-value pair tells us whether the match was a qualification or playoff match. We can use a list comprehension to get a list of all the *comp_level* codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f',\n",
       " 'f',\n",
       " 'qf',\n",
       " 'qf',\n",
       " 'qf',\n",
       " 'qf',\n",
       " 'qf',\n",
       " 'qf',\n",
       " 'qf',\n",
       " 'qf',\n",
       " 'qf',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'qm',\n",
       " 'sf',\n",
       " 'sf',\n",
       " 'sf',\n",
       " 'sf']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all match competition levels\n",
    "[mtch[\"comp_level\"] for mtch in matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a long list. We just want to see what values the *comp_level* field can be. We don't need the entire list. Fortunately Python provides an easy way to extract only the unique items from a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f', 'qf', 'qm', 'sf'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique competition levels\n",
    "set([mtch[\"comp_level\"] for mtch in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better. There are four types of matches in the dataset: qualification (qm), quarter-finals (qf), semi-finals (sf), and finals (f).\n",
    "\n",
    "The built-in `set()` function converts its argument to a new composite data type that we have not previously discussed. Python sets are similar to lists, except they are not allowed to have duplicate values. Sets can be created witht the `set()` function or by placing the desired contents within curly braces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a set\n",
    "myset = {1, 2, 2, 3, 3, 3, 4, 4, 4, 4}\n",
    "print(type(myset))\n",
    "myset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. List of Match Scores\n",
    "Suppose we are interested only in the total points scored by the red and blue alliances for qualificatio matches. The following list comprehension will extract that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'match_number': 1, 'totalPoints_blue': 69, 'totalPoints_red': 22},\n",
       " {'match_number': 10, 'totalPoints_blue': 53, 'totalPoints_red': 65},\n",
       " {'match_number': 11, 'totalPoints_blue': 91, 'totalPoints_red': 41},\n",
       " {'match_number': 12, 'totalPoints_blue': 59, 'totalPoints_red': 57},\n",
       " {'match_number': 13, 'totalPoints_blue': 57, 'totalPoints_red': 59},\n",
       " {'match_number': 14, 'totalPoints_blue': 84, 'totalPoints_red': 10},\n",
       " {'match_number': 15, 'totalPoints_blue': 186, 'totalPoints_red': 44},\n",
       " {'match_number': 16, 'totalPoints_blue': 33, 'totalPoints_red': 86},\n",
       " {'match_number': 17, 'totalPoints_blue': 107, 'totalPoints_red': 61},\n",
       " {'match_number': 18, 'totalPoints_blue': 89, 'totalPoints_red': 77}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List Comprehension for total scores\n",
    "total_scores = [{\"match_number\": mtch[\"match_number\"],\n",
    "                 \"totalPoints_blue\": mtch[\"score_breakdown\"][\"blue\"][\"totalPoints\"],\n",
    "                 \"totalPoints_red\": mtch[\"score_breakdown\"][\"red\"][\"totalPoints\"]}\n",
    "                for mtch in matches if mtch[\"comp_level\"] == \"qm\"]\n",
    "total_scores[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how we built a dictionary within the list comprehension?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Using a Nested Comprehension\n",
    "Suppose we just want a list of all teams that participated in the competition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['frc2930', 'frc2976', 'frc4918'],\n",
       " ['frc2930', 'frc2976', 'frc4918'],\n",
       " ['frc4512', 'frc949', 'frc4131'],\n",
       " ['frc4512', 'frc949', 'frc4131'],\n",
       " ['frc1318', 'frc4513', 'frc7461']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple list comprehension to extract blue alliance teams\n",
    "blue_alliances = [mtch[\"alliances\"][\"blue\"][\"team_keys\"] for mtch in matches]\n",
    "blue_alliances[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not bad, but it's still a list of lists, with a lot of duplication. We would prefer just a simple, flat list. A nested list comprehension can help us achieve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frc2930', 'frc2930', 'frc4512', 'frc4512', 'frc1318']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nested list comprehension\n",
    "blue_teams_1 = [teams[0] for teams in [mtch[\"alliances\"][\"blue\"][\"team_keys\"] for mtch in matches]]\n",
    "blue_teams_1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see what we did here? We embedded a list comprehension within another list comprehension. The inner comprehension extracted the blue alliance teams into a nested list, and the outer comprehension extracted the first element of each inner list. Nesting comprehensions enables sophisticated transformations of data. But we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frc2930',\n",
       " 'frc2976',\n",
       " 'frc4918',\n",
       " 'frc2930',\n",
       " 'frc2976',\n",
       " 'frc4918',\n",
       " 'frc4512',\n",
       " 'frc949',\n",
       " 'frc4131',\n",
       " 'frc4512']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_teams = [team for teams in [mtch[\"alliances\"][\"blue\"][\"team_keys\"] for mtch in matches] for team in teams]\n",
    "blue_teams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is confusing, but it gave us exactly what we want. All teams have been extracted into a single flat list. There are now two `for` expressions in the outer comprehension. The syntax will make more sense if we compare the comprehension to the equivalent `for` loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frc2930',\n",
       " 'frc2976',\n",
       " 'frc4918',\n",
       " 'frc2930',\n",
       " 'frc2976',\n",
       " 'frc4918',\n",
       " 'frc4512',\n",
       " 'frc949',\n",
       " 'frc4131',\n",
       " 'frc4512']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_teams = []\n",
    "for teams in [mtch[\"alliances\"][\"blue\"][\"team_keys\"] for mtch in matches]:\n",
    "    for team in teams:\n",
    "        blue_teams.append(team)\n",
    "              \n",
    "blue_teams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `for` expressions in the list comprehension are placed in the same order that we would use if we were writing traditional nested `for` statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Exercises\n",
    "Several of the following exercises require you to create text or JSON files. Make a subfolder called *s10_files* and make sure your code saves the files to that folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9.1\n",
    "Create a string variable containing JSON text. The JSON string should contain a list of dictionary objects. Each dictionary object should represent a country of your choice. It should have keys and values for:\n",
    "* The country's name\n",
    "* The country's capitol\n",
    "* Famous persons from that country. This value should contain a nested list with two or more famous person.\n",
    "\n",
    "Pass the string variable to the `json.dumps()` method to verify the syntax is correct.\n",
    "\n",
    "Remember, string values must be contained within double quotes. You can see the syntax rules for JSON at [json.org](http://json.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '', 'country capital': '', 'Famous persons': []}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex 9.1\n",
    "import json\n",
    "json_string = {\"country\": \"\", \"country capital\": \"\", \"Famous persons\": []}\n",
    "json_string = json.dumps(json_string)\n",
    "# Create JSON string here\n",
    "\n",
    "# Leave this line alone.\n",
    "# You will see an error if there is an error in your json string.\n",
    "# Otherwise the json object will be displayed.\n",
    "json.loads(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9.2\n",
    "Use a list comprehension to create a list of tuples. Each tuple will have four items: 1) the *comp_level*, 2) the *match_number*, 3) the blue alliance score, and 4) the red alliance score. Save the list to a variable named `match_scores` and display the first six list elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f', 1, 136, 148),\n",
       " ('f', 2, 137, 163),\n",
       " ('qf', 1, 122, 193),\n",
       " ('qf', 2, 95, 140),\n",
       " ('qf', 1, 134, 89),\n",
       " ('qf', 2, 191, 128)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex 9.2\n",
    "match_scores = [(mtch[\"comp_level\"], mtch[\"match_number\"], mtch[\"alliances\"][\"blue\"][\"score\"],\n",
    "                mtch[\"alliances\"][\"red\"][\"score\"]) for mtch in matches]\n",
    "match_scores[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9.3\n",
    "Save the list you created in **Ex IV.1** to a file using the JSON package. Name the file *match_scores.json*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 9.3\n",
    "with open(\"match_scores.json\", \"w\") as scores:\n",
    "    json.dump(match_scores, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9.4\n",
    "Open the match_scores.json file using the json package. When opening the file, assign the contents to a variable called `match_scores2`. Display the last five elements in the `match_scores2` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['qm', 9, 64, 113],\n",
       " ['sf', 1, 139, 171],\n",
       " ['sf', 2, 94, 137],\n",
       " ['sf', 1, 147, 130],\n",
       " ['sf', 2, 158, 91]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex 9.4\n",
    "with open(\"match_scores.json\", \"r\") as scores:\n",
    "    match_scores2 = json.load(scores)\n",
    "match_scores2[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9.5\n",
    "Save the `match_scores2` list you created in **EX IV.3** to a text file called *match_scores.txt* (do not use the JSON module). Each row of the file should contain one tuple. Don't forget that each row needs to end with a newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f', 1, 136, 148] \n",
      "\n",
      "['f', 2, 137, 163] \n",
      "\n",
      "['qf', 1, 122, 193] \n",
      "\n",
      "['qf', 2, 95, 140] \n",
      "\n",
      "['qf', 1, 134, 89] \n",
      "\n",
      "['qf', 2, 191, 128] \n",
      "\n",
      "['qf', 1, 130, 133] \n",
      "\n",
      "['qf', 2, 132, 68] \n",
      "\n",
      "['qf', 3, 79, 83] \n",
      "\n",
      "['qf', 1, 130, 95] \n",
      "\n",
      "['qf', 2, 137, 32] \n",
      "\n",
      "['qm', 1, 69, 22] \n",
      "\n",
      "['qm', 10, 53, 65] \n",
      "\n",
      "['qm', 11, 91, 41] \n",
      "\n",
      "['qm', 12, 59, 57] \n",
      "\n",
      "['qm', 13, 57, 59] \n",
      "\n",
      "['qm', 14, 84, 10] \n",
      "\n",
      "['qm', 15, 186, 44] \n",
      "\n",
      "['qm', 16, 33, 86] \n",
      "\n",
      "['qm', 17, 107, 61] \n",
      "\n",
      "['qm', 18, 89, 77] \n",
      "\n",
      "['qm', 19, 30, 57] \n",
      "\n",
      "['qm', 2, 45, 91] \n",
      "\n",
      "['qm', 20, 146, 39] \n",
      "\n",
      "['qm', 21, 93, 84] \n",
      "\n",
      "['qm', 22, 82, 74] \n",
      "\n",
      "['qm', 23, 64, 57] \n",
      "\n",
      "['qm', 24, 80, 110] \n",
      "\n",
      "['qm', 25, 71, 46] \n",
      "\n",
      "['qm', 26, 31, 220] \n",
      "\n",
      "['qm', 27, 82, 79] \n",
      "\n",
      "['qm', 28, 56, 105] \n",
      "\n",
      "['qm', 29, 49, 89] \n",
      "\n",
      "['qm', 3, 12, 65] \n",
      "\n",
      "['qm', 30, 49, 82] \n",
      "\n",
      "['qm', 31, 112, 107] \n",
      "\n",
      "['qm', 32, 100, 57] \n",
      "\n",
      "['qm', 33, 36, 112] \n",
      "\n",
      "['qm', 34, 19, 93] \n",
      "\n",
      "['qm', 35, 49, 29] \n",
      "\n",
      "['qm', 36, 80, 121] \n",
      "\n",
      "['qm', 37, 71, 118] \n",
      "\n",
      "['qm', 38, 97, 109] \n",
      "\n",
      "['qm', 39, 48, 145] \n",
      "\n",
      "['qm', 4, 84, 98] \n",
      "\n",
      "['qm', 40, 117, 67] \n",
      "\n",
      "['qm', 41, 69, 92] \n",
      "\n",
      "['qm', 42, 36, 80] \n",
      "\n",
      "['qm', 43, 32, 99] \n",
      "\n",
      "['qm', 44, 56, 42] \n",
      "\n",
      "['qm', 45, 40, 80] \n",
      "\n",
      "['qm', 46, 156, 39] \n",
      "\n",
      "['qm', 47, 128, 102] \n",
      "\n",
      "['qm', 48, 85, 58] \n",
      "\n",
      "['qm', 49, 142, 79] \n",
      "\n",
      "['qm', 5, 16, 64] \n",
      "\n",
      "['qm', 50, 81, 169] \n",
      "\n",
      "['qm', 51, 120, 121] \n",
      "\n",
      "['qm', 52, 63, 66] \n",
      "\n",
      "['qm', 53, 98, 62] \n",
      "\n",
      "['qm', 54, 144, 92] \n",
      "\n",
      "['qm', 55, 81, 55] \n",
      "\n",
      "['qm', 56, 100, 63] \n",
      "\n",
      "['qm', 57, 83, 97] \n",
      "\n",
      "['qm', 58, 64, 141] \n",
      "\n",
      "['qm', 59, 67, 88] \n",
      "\n",
      "['qm', 6, 69, 132] \n",
      "\n",
      "['qm', 60, 74, 75] \n",
      "\n",
      "['qm', 61, 80, 127] \n",
      "\n",
      "['qm', 62, 80, 68] \n",
      "\n",
      "['qm', 63, 152, 107] \n",
      "\n",
      "['qm', 64, 20, 74] \n",
      "\n",
      "['qm', 65, 140, 177] \n",
      "\n",
      "['qm', 66, 44, 57] \n",
      "\n",
      "['qm', 67, 136, 35] \n",
      "\n",
      "['qm', 68, 75, 69] \n",
      "\n",
      "['qm', 69, 141, 40] \n",
      "\n",
      "['qm', 7, 127, 125] \n",
      "\n",
      "['qm', 70, 57, 83] \n",
      "\n",
      "['qm', 71, 75, 133] \n",
      "\n",
      "['qm', 72, 63, 125] \n",
      "\n",
      "['qm', 73, 121, 57] \n",
      "\n",
      "['qm', 74, 121, 126] \n",
      "\n",
      "['qm', 8, 32, 29] \n",
      "\n",
      "['qm', 9, 64, 113] \n",
      "\n",
      "['sf', 1, 139, 171] \n",
      "\n",
      "['sf', 2, 94, 137] \n",
      "\n",
      "['sf', 1, 147, 130] \n",
      "\n",
      "['sf', 2, 158, 91] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ex 9.5\n",
    "with open(\"match_scores.txt\", \"wt\") as scores:\n",
    "    for mtch in match_scores2:\n",
    "        line = str(mtch) + \"\\n\"\n",
    "        scores.write(line)\n",
    "        print(mtch, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9.6\n",
    "Use the `match_scores2` list and a list comprehension to create a list of combined match scores (i.e., the sum of the blue alliance and red alliance scores). Don't worry about tracking the matches. Then use the built-in `max()` function to find the highest combined score for a match. Finally, use the built-in `min()` function to find the lowest combined score for a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "# Ex 9.6m\n",
    "mtch_both =[]\n",
    "mtch_red = [mtch[2] for mtch in match_scores2]\n",
    "mtch_blue = [mtch[3] for mtch in match_scores2]\n",
    "for mtch in match_scores:\n",
    "    mtch_both.append(int(str(mtch[2])) + int(str(mtch[3])))\n",
    "print(max(mtch_both))\n",
    "print(min(mtch_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9.7\n",
    "Open the *match_scores.txt* file. Iterate through each row of the file and find the match (i.e., competition level and match number) that had the highest combined score. Also find the match that had the lowest combined score. \n",
    "\n",
    "This one is tricky. Here are some hints.\n",
    "* Use string indexing to stript the beginning and ending square brackets from each line.\n",
    "* Use the `str.split()` method to split the string between the commas. See the [documentation for `str.split()` here](https://docs.python.org/3/library/stdtypes.html?highlight=split#str.split).\n",
    "* Don't forget to convert data types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65 317\n"
     ]
    }
   ],
   "source": [
    "# Ex 9.7\n",
    "score = {}\n",
    "with open(\"match_scores.txt\", \"rt\") as mtch_scores:\n",
    "    for matches in mtch_scores.readlines():\n",
    "        mtch = matches[1:-2]\n",
    "        mtch = mtch.split(\",\")\n",
    "        comp_match = {mtch[1]:int(mtch[2]) + int(mtch[3])}\n",
    "        score.update(comp_match)\n",
    "    max_key = max(score, key=score.get)\n",
    "    max_value = max(score.values())\n",
    "    print(max_key, max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 9.8\n",
    "The time values in the matches JSON data are all big integers, like *1583104716*. These are UNIX style time stamps. A UNIX timestamp is the number of seconds that have elapsed since 00:00 a.m. on January 1st, 1970. Use a list comprehension and methods from the `datetime` module in the standard library to build a list of match start times that is human readable.\n",
    "* You will need to review the [documentation for the datetime module](https://docs.python.org/3/library/datetime.html).\n",
    "* Check out the `datetime.fromtimestamp()` method.\n",
    "* Also check out the `datetime.strftime()` method.\n",
    "* It seems redudent, but the `datetime` module contains a `datetime` class. This is an important detail if you want your code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['March, 01, 2020, 15:18:36',\n",
       " 'March, 01, 2020, 15:56:12',\n",
       " 'March, 01, 2020, 13:03:52',\n",
       " 'March, 01, 2020, 13:38:43',\n",
       " 'March, 01, 2020, 13:13:35',\n",
       " 'March, 01, 2020, 13:47:30',\n",
       " 'March, 01, 2020, 13:20:22',\n",
       " 'March, 01, 2020, 14:00:29',\n",
       " 'March, 01, 2020, 14:20:27',\n",
       " 'March, 01, 2020, 13:31:40',\n",
       " 'March, 01, 2020, 14:07:20',\n",
       " 'February, 29, 2020, 11:04:24',\n",
       " 'February, 29, 2020, 12:39:12',\n",
       " 'February, 29, 2020, 12:47:13',\n",
       " 'February, 29, 2020, 12:56:47',\n",
       " 'February, 29, 2020, 13:07:26',\n",
       " 'February, 29, 2020, 13:17:49',\n",
       " 'February, 29, 2020, 14:07:40',\n",
       " 'February, 29, 2020, 14:15:20',\n",
       " 'February, 29, 2020, 14:22:20',\n",
       " 'February, 29, 2020, 14:29:26',\n",
       " 'February, 29, 2020, 14:37:37',\n",
       " 'February, 29, 2020, 11:16:52',\n",
       " 'February, 29, 2020, 14:45:04',\n",
       " 'February, 29, 2020, 14:53:53',\n",
       " 'February, 29, 2020, 15:02:23',\n",
       " 'February, 29, 2020, 15:09:56',\n",
       " 'February, 29, 2020, 15:16:37',\n",
       " 'February, 29, 2020, 15:23:21',\n",
       " 'February, 29, 2020, 15:33:08',\n",
       " 'February, 29, 2020, 15:42:19',\n",
       " 'February, 29, 2020, 15:48:45',\n",
       " 'February, 29, 2020, 15:56:40',\n",
       " 'February, 29, 2020, 11:27:30',\n",
       " 'February, 29, 2020, 16:06:05',\n",
       " 'February, 29, 2020, 16:13:22',\n",
       " 'February, 29, 2020, 16:29:29',\n",
       " 'February, 29, 2020, 16:38:58',\n",
       " 'February, 29, 2020, 16:47:06',\n",
       " 'February, 29, 2020, 16:55:32',\n",
       " 'February, 29, 2020, 17:02:51',\n",
       " 'February, 29, 2020, 17:10:45',\n",
       " 'February, 29, 2020, 17:19:35',\n",
       " 'February, 29, 2020, 17:27:24',\n",
       " 'February, 29, 2020, 20:07:29',\n",
       " 'February, 29, 2020, 17:34:11',\n",
       " 'February, 29, 2020, 17:41:20',\n",
       " 'February, 29, 2020, 17:48:51',\n",
       " 'February, 29, 2020, 17:58:01',\n",
       " 'February, 29, 2020, 18:04:52',\n",
       " 'February, 29, 2020, 18:13:34',\n",
       " 'February, 29, 2020, 18:20:56',\n",
       " 'February, 29, 2020, 18:28:21',\n",
       " 'February, 29, 2020, 18:35:46',\n",
       " 'February, 29, 2020, 18:42:23',\n",
       " 'February, 29, 2020, 11:46:48',\n",
       " 'February, 29, 2020, 18:49:53',\n",
       " 'February, 29, 2020, 18:56:39',\n",
       " 'February, 29, 2020, 19:04:02',\n",
       " 'February, 29, 2020, 19:11:50',\n",
       " 'February, 29, 2020, 19:19:04',\n",
       " 'February, 29, 2020, 19:28:44',\n",
       " 'February, 29, 2020, 19:35:05',\n",
       " 'February, 29, 2020, 19:41:12',\n",
       " 'February, 29, 2020, 19:48:09',\n",
       " 'February, 29, 2020, 19:55:42',\n",
       " 'February, 29, 2020, 11:58:22',\n",
       " 'March, 01, 2020, 09:35:18',\n",
       " 'March, 01, 2020, 09:43:02',\n",
       " 'March, 01, 2020, 09:49:51',\n",
       " 'March, 01, 2020, 09:56:41',\n",
       " 'March, 01, 2020, 10:07:05',\n",
       " 'March, 01, 2020, 10:13:30',\n",
       " 'March, 01, 2020, 10:23:48',\n",
       " 'March, 01, 2020, 10:30:49',\n",
       " 'March, 01, 2020, 10:38:15',\n",
       " 'March, 01, 2020, 10:46:28',\n",
       " 'February, 29, 2020, 12:08:12',\n",
       " 'March, 01, 2020, 10:55:48',\n",
       " 'March, 01, 2020, 11:04:34',\n",
       " 'March, 01, 2020, 11:11:06',\n",
       " 'March, 01, 2020, 11:18:17',\n",
       " 'March, 01, 2020, 11:34:20',\n",
       " 'February, 29, 2020, 12:21:14',\n",
       " 'February, 29, 2020, 12:29:27',\n",
       " 'March, 01, 2020, 14:30:03',\n",
       " 'March, 01, 2020, 14:47:38',\n",
       " 'March, 01, 2020, 14:40:23',\n",
       " 'March, 01, 2020, 14:56:15']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex 9.8\n",
    "from datetime import datetime;\n",
    "[mtch1.strftime(\"%B, %d, %Y, %X\") for mtch1 in [datetime.fromtimestamp(match) for match in [mtch[\"actual_time\"] for mtch in matches]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Quiz\n",
    "Enter your answers as comments in the code cells below each question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1.** What is the absolute path of this notebook file on your computer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 \n",
    "# C:\\Users\\pperv\\Desktop\\Robotics\\Robotics Training\\pyclass_frc\\sessions\\s09_files_and_comprehensions\\s09_files_and_comprehensions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2.** What is the relative path of the session 2 notebook, *s02_data_types.ipynb* from this notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "# ../s02_data_types/s02_data_types.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3.** In general, is it better to use absolute or relative paths in computer programs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "# Relative paths as absolute paths will only allow specific users to use the computer programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#4.** Why is it beneficial to use the `with` statement when opening or saving to files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "# The with file makes sure to closes the file when the code is done running or when the code produces an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#5.** What does putting an exclamation mark, `!`, at the beginning of a line in a code cell do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "# We can run CLI commands from Jupyter Notebook using the !."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#6.** What module must be imported in order to change the current working directory? What is the command for changing the current working directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "# You have to import the os module.The command to change the current working directory is os.chdir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#7.** Earlier in the notebook there was a cell that contained the statement `os.chdir(\"misc_files\")`. The cell runs one time with no problems. But if you try to run it a second time, it throws an error. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "# You can't change the directory to a directory you are currently working in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#8.** What will each of the following strings look like when printed? Type out what you thing the output will be in your answer.\n",
    "* \"1/n2\\n3\"\n",
    "* \"1\\n2\\\\\\\\n3\"\n",
    "* \"\\\\\"1\\\\\"\\\\\\\\m2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "#1/n2\n",
    "#3\n",
    "\n",
    "#1\n",
    "#2\\n3\n",
    "\n",
    "#\"1\"\\m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#9.** The last code example in section 1.D demonstrated how to read a file line by line. Would it be a good idea to use this technique to read the *matches.json* file? Why or why not? (HINT: How many newline characters are in *matches.json*?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "#It would not be a good idea because each line contains a dictionary item or a list value and then moves to the next line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#10.** What 1970's operating system greatly influencd MS-DOS, and subsequently Microsoft Windows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "#CP/M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Save Your Work\n",
    "Once you have completed the exercises, save a copy of the notebook and the two files you created (*match_scores.json* and *match_scores.txt*) outside of the git repository (outside of the *pyclass_frc* folder). Upload the files to your git assignments repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Concept and Terminology Review\n",
    "You should be able to define the following terms or describe the concept.\n",
    "* Built-in `open()` function\n",
    "* File read and write modes\n",
    "* Relative and absolute file paths\n",
    "* Understanding Python's working directory\n",
    "* Changing the working directory\n",
    "* Closing files\n",
    "* Using the `with` statement to work with files\n",
    "* Newline characters\n",
    "* Inserting newlines in strings\n",
    "* Javascript Object Notation (JSON)\n",
    "* Python's json package\n",
    "* List and dictionary comprehensions\n",
    "* Filtering within comprehensions\n",
    "* Nested and multi-level comprehensions\n",
    "* Python's built-in `min()` and `max()` functions\n",
    "* Converting Unix timestamps with Python's datetime module\n",
    "* The `str.split()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](../../index.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
